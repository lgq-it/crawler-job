# crawler-job #
这是一套分布式的，前后端分离项目，由于前端处理的太草率了，就不展示给大家看！现在这个是后端项目
目前能爬取前程无忧，以及猎聘网中关于java的招聘信息，总共开辟了5个微服务，由于项目是个简单爬取
功能也就简单的使用了一下，并未涉及到高并发这一点，所以没有使用熔断以及降级；
## 以下是端口描述 ## 
+ 10086 – - eureka  服务的注册和散发中心 
+ 10087 –- zuul   网关微服务 
+ 8081 – - item-pull-service 拉取各大网站数据并保存在数据库，由于各大网站数据过大，所以单独提取成一个服务；主要负责数据库中的写操作
+ 8082 –- iem-show-data  数据显示微服务 – 后续搜索功能改成全文检索技术，使用search服务;主要负责数据库中的查操作； 该模块使用swagger生成了api文档
+ 8083 –-search  使用全文检索技术elasticSearch，作为数据的查询功能；搜索流程，先根据关键字进行查询，再进行过滤条件过滤，最后根据你需要的条件进行聚合为桶，将聚合好后的数据进行整理，就是可选的查询条件；该模块使用swagger生成了api文档
## 使用问题 ## 
1. 数据库相关:该项目使用的是springDataJpa作为持久层框架，可以自行设置是否生成表操作  
2. 若是要运行该项目，除了要更改数据库的用户名以及密码外还要更改es索引库以及rabbitMq消息队列的端口，现在正在努力学习springcloud中的config组件，让这个功能的配置文件更改的更加方便
